#!/usr/bin/env python3# -*- coding: utf-8 -*-"""Created on Sat Mar  9 17:34:34 2024@author: fangyixuan huang"""import numpy as npimport pandas as pdfrom sklearn.preprocessing import MinMaxScalerfrom sklearn.metrics import mean_squared_errorfrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Dense, LayerNormalization, Dropout, MultiHeadAttention, Inputimport tensorflow as tfimport matplotlib.pyplot as pltfrom tensorflow.keras.optimizers import Adamdef transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):    # Attention and Normalization    x = LayerNormalization(epsilon=1e-6)(inputs)    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)    x = Dropout(dropout)(x)    res = x + inputs    # Feed Forward and Normalization    x = LayerNormalization(epsilon=1e-6)(res)    x = Dense(ff_dim, activation="relu")(x)    x = Dropout(dropout)(x)    x = Dense(inputs.shape[-1])(x)    return x + resdef Trans_build_model(sequence_length, features, head_size=64, num_heads=4, ff_dim=64, num_blocks=4, dropout=0.1):    inputs = Input(shape=(sequence_length, features))    x = inputs    for _ in range(num_blocks):        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)    outputs = Dense(1)(x)    model = tf.keras.Model(inputs=inputs, outputs=outputs)    return modeldef Trans_build_and_predict(data, future_steps=1):    # Preprocess the data 正则化数据    scaler = MinMaxScaler(feature_range=(-1, 1))    scaled_data = scaler.fit_transform(data['Close'].values.reshape(-1,1))    X, y = [], []    sequence_length = future_steps    for i in range(len(scaled_data) - sequence_length):        X.append(scaled_data[i:i+sequence_length])        y.append(scaled_data[i+sequence_length])    X, y = np.array(X), np.array(y)    # Split the data (Here, using the last 30% of data for testing as an example)    #70训练 30测试    train_size = int(len(X) * 0.7)    X_train, X_test = X[:train_size], X[train_size:]    y_train, y_test = y[:train_size], y[train_size:]    # Build the model 建模型    model = Trans_build_model(sequence_length, 1)    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')    # Train the model 训练模型    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)    # Predict future values 预测    train_predict = model.predict(X_train)    test_predict = model.predict(X_test)        #train_predict = train_predict.reshape(train_predict.shape[0],train_predict.shape[1])    #test_predict = test_predict.reshape(test_predict.shape[0],test_predict.shape[1])    #从三维数据（2000，1，1）变成（2000，1）即挤掉最后一层 如果是预测steps=5 就是（2000，5，1）    train_predict = train_predict.squeeze(axis=-1)    test_predict = test_predict.squeeze(axis=-1)    return y_train, y_test, train_predict, test_predict, scalerdef main():     # Load the dataset    df = pd.read_csv('./archive/coin_Bitcoin.csv')        # Call the build_and_predict function    # 通过改future_steps来改预测步数    y_train, y_test, train_predict, test_predict, scaler = Trans_build_and_predict(df, future_steps=1)            # Calculate RMSE    train_rmse = np.sqrt(np.mean((y_train.flatten()-train_predict.flatten())**2))    print("Train RMSE:", train_rmse)    # 计算测试集RMSE    test_rmse = np.sqrt(np.mean((y_test.flatten()-test_predict.flatten())**2))    print("Test RMSE:",test_rmse)        # Invert predictions back to original scale        train_predict_inv = scaler.inverse_transform(train_predict)    y_train_inv = scaler.inverse_transform(y_train)    test_predict_inv = scaler.inverse_transform(test_predict)    y_test_inv = scaler.inverse_transform(y_test)            # Plotting the results    #画图 训练集的预测值和实际值    plt.figure(figsize=(15,6))    plt.plot(y_train_inv.flatten(), label='Train actual')    plt.plot(train_predict_inv.flatten(), label='Train predictions')    plt.legend()    plt.show()        #测试集的预测值和实际值    plt.figure(figsize=(15,6))    plt.plot(y_test_inv.flatten(), label='Test actual')    plt.plot(test_predict_inv.flatten(), label='Test predictions')    plt.legend()    plt.show()if __name__ == '__main__':    main()